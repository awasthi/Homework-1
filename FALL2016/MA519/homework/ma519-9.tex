\begin{problem}[Handout 13, \# 7]
  Let \(X\) have a \emph{double exponential} density
  \(f(x)=\frac{1}{2\sigma}\rme^{-\frac{|x|}{\sigma}}\),
  \(-\infty<x<\infty\), \(\sigma>0\).
  \begin{enumerate}[label=(\alph*),noitemsep]
  \item Show that all moments exist for this distribution.
  \item However, show that the MGF exists only for restricted
    values. Identify them and find a formula.
  \end{enumerate}
\end{problem}
\begin{solution}
  For part (a), we show that the moments \(m_n\defeq E(X^n)\) for all
  \(n\in\bbN\). By direct calculation, we have
  \begin{align*}
    m_n
    &=\int_{-\infty}^\infty x^nf(x)\diff x\\
    &=\int_{-\infty}^\infty
      \frac{x^n}{2\sigma}\rme^{-\frac{|x|}{\sigma}}\diff x\\
    &=\underbrace{\int_{-\infty}^0\frac{x^n}{2\sigma}\rme^{\frac{x}{\sigma}}\diff x}_L
      +\int_0^\infty\frac{x^n}{2\sigma}\rme^{-\frac{x}{\sigma}}\diff x,
      \intertext{making the substitution \(x\mapsto -y\) to \(L\) and relabeling
      \(y\) to \(x\) again, the above becomes}
    &=\int_0^\infty\frac{x^n+(-1)x^n}{2\sigma}\rme^{-\frac{x}{\sigma}}\diff x\\
    &=\begin{cases}
      0&\text{if \(n\) is odd,}\\
      I\defeq\int_0^\infty \frac{x^n}{\sigma}\rme^{-\frac{x}{\sigma}}\diff x&
      \text{if \(n=2k\) is even.}
      \end{cases}
  \end{align*}
  To evaluate \(I\) we apply integration by parts repeatedly to arrive at
  \begin{align*}
    I
    &=\int_{-\infty}^0\frac{x^n}{\sigma}\rme^{-\frac{x}{\sigma}}\\
    &=(-0+0)+\int_0^\infty
      n\sigma x^{n-1}\rme^{-\frac{x}{\sigma}}\diff x\\
    &=(-0+0)+(-0+0)+\int_0^\infty
      n(n-1)\sigma^2 x^{n-1}\rme^{-\frac{x}{\sigma}}\diff x
    &\vdotswithin{=}\\
    &=(-0-0)+\dotsb+(-0+0)+(-0+n!\sigma^n)\\
    &=n!\sigma^n.
  \end{align*}
  Therefore, \(m_n\) exist and are finite for all \(n\in\bbN\).

  Fr part (b), the MGF associated to \(f\) is given by the series
  \begin{equation}
    \label{eq:9:mgf-double-exp}
    m(t)=%
    \sum_{n=0}^\infty \frac{t^nm_n}{n!}=%
    \sum_{k=1}^\infty t^{2k}\sigma^{2k}.
  \end{equation}
  This series is geometric and, as such, converges for all
  \(|t|<\frac{1}{\sigma}\), in which case \eqref{eq:9:mgf-double-exp}
  becomes
  \[
    m(t)=\frac{1}{1-t^2\sigma^2}.\qedhere
  \]
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 10]
  Suppose \(X\) has Cauchy distribution as in \# 6. Which of the following
  functions have finite expectation
  \[
    \begin{aligned}
      X;&&-X;&&|X|;&&\frac{1}{X};&&\sin X;&&\ln|X|;&&\rme^X;&&\rme^{-|X|}?
    \end{aligned}
  \]
\end{problem}
\begin{solution}
  Suppose \(X\sim\Cauchy(0,1)\). Then the PDF of \(X\) is given by the
  expression
  \[
    f(x)=\frac{1}{\pi(x^2+1)}.
  \]
  Now we proceed to find the expectations of (i) \(X\), (ii) \(-X\),
  (iii) \(\frac{1}{X}\), (iv) \(\sin X\), (v) \(\ln|X|\), (vi) \(\rme^X\),
  (vii) \(\rme^{{-}|X|}\).

  For (i), the expectation does not exist. Consider
  \[
    E(X)
    =\frac{1}{\pi}\int_{-\infty}^\infty \frac{x}{x^2+1}\diff x
    =\lim_{x_1,x_2\to\infty}\frac{1}{\pi}\int_{-x_1}^{x_2}\frac{x}{x^2+1}\diff x.
  \]
  Then, making the substitution \(u=x^2+1\), \(du=2x\diff x\), the integral
  above evaluates to
  \[
    E(X)=\lim_{x_1,x_2\to\infty}\frac{1}{2\pi}\ln\left(\frac{x_2^2+1}{x_1^2+1}\right).
  \]
  However, the limit of this expression is undefined! Fix positive real
  number \(\alpha\) and let \(x_2=\alpha x_1\). Then
  \[
    E(X)=%
    \lim_{x_1\to\infty}\frac{1}{2\pi}\ln\left(\frac{\alpha^2x_1^2+1}{x_1^2+1}\right)=%
    \frac{1}{2\pi}\ln\alpha^2.
  \]
  The value of this limit is distinct for each \(\alpha\). This contradicts
  the uniqueness of the limit and therefore, the limit must not exist.

  For the rest of these ((ii) through (viii)), we
  use Theorem 1.33 to forgo computing the PDF.

  For (ii), we have
  \[
    E(-X)=\int_{-\infty}^\infty -xf(x)\diff x=-E(X).
  \]
  Thus, \(E(-X)\) is also undefined.

  For (iii), we have
  \begin{align*}
    E(|X|)
    &=\frac{1}{\pi}\int_{-\infty}^\infty\frac{|x|}{x^2+1}\diff x\\
    &=\frac{2}{\pi}\int_0^\infty\frac{x}{x^2+1}\diff x\\
    &=\lim_{\xi\to\infty}\frac{2}{\pi}\ln(\xi^2+1)\\
    &=\infty.
  \end{align*}

  For (iv), we have
  \begin{align*}
    E\left(\frac{1}{X}\right)
    &=\frac{1}{\pi}\int_{-\infty}^\infty\frac{1}{x(x^2+1)}\diff x\\
    &=\lim_{x_1,x_2\to\infty}\ln\left(\frac{x_2}{\sqrt{x_1^2+1}}\right)
  \end{align*}
  which is undefined. In fact, one can show that
  \(\frac{1}{X}\sim\Cauchy(0,1)\): First, let us find the CDF of
  \(\frac{1}{X}\)
  \begin{align*}
    F_{\frac{1}{X}}(x)
    &=P\left(\frac{1}{X}\leq x\right)\\
    &=P\left(X\geq\frac{1}{x}\right)\\
    &=1-P\left(X<\frac{1}{x}\right)\\
    &=1-\frac{1}{\pi}\int_{-\infty}^{\frac{1}{x}}\frac{1}{y^2+1}\diff y\\
    &=1-\tan^{-1}\left(\frac{1}{x}\right)-\frac{1}{2}\\
    &=\frac{1}{2}-\tan^{-1}\left(\frac{1}{x}\right).
  \end{align*}
  Thus, the PDF of \(\frac{1}{X}\) is
  \begin{align*}
    f_{\frac{1}{X}}(x)
    &=\frac{dF_{\frac{1}{X}}(x)}{dx}\\
    &=-\left(-\frac{1}{x^2}\right)\left(\frac{1}{\left(\frac{1}{x}\right)^2+1}\right)\\
    &=\frac{1}{x^2+1}.
  \end{align*}
  Thus, \(\frac{1}{X}\sim\Cauchy(0,1)\) giving us another argument for why
  \(E(\frac{1}{X})\) is undefined.

  For (v), we have
  \begin{align*}
    E(\sin X)
    &=\frac{1}{\pi}\int_{-\infty}^\infty \frac{\sin x}{x^2+1}\diff x\\
    &\leq\frac{1}{\pi}\int_{-\infty}^\infty\frac{|\sin x|}{x^2+1}\diff x
      \intertext{since \(|{\sin x}|\leq 1\), we further have}
    &\leq\frac{1}{\pi}\int_{-\infty}^\infty\frac{1}{x^2+1}\diff x\\
    &=\frac{1}{\pi}\left(\frac{\pi}{2}-\left(-\frac{\pi}{2}\right)\right)\\
    &=1.
  \end{align*}
  Thus, \(E(\sin X)\) exists and is finite.

  For (vi), note that \(\ln|X|\) by symmetry,
  \begin{align*}
    E({\ln|X|})
    &=\frac{1}{\pi}\int_{-\infty}^\infty\frac{\ln|x|}{x^2+1}\diff x\\
    &=\frac{2}{\pi}\int_0^\infty\frac{\ln x}{x^2+1}\diff x
    \intertext{making the substitution \(\theta=\tan^{-1}x\),
      \((x^2+1)\diff \theta=\diff x\), we have}
    &=\int_0^{\frac{\pi}{2}}\ln\left({\tan\theta}\right)\diff\theta\\
    &=\int_0^{\frac{\pi}{2}}\ln(\sin\theta)\diff\theta
      -\int_0^{\frac{\pi}{2}}\ln(\cos\theta)\diff\theta\\
    &=\int_0^{\frac{\pi}{2}}\ln(\sin\theta)\diff\theta
      -\int_0^{\frac{\pi}{2}}\ln\left(\sin\left(\frac{\pi}{2}-\theta\right)
      \right)\diff\theta
      \intertext{making the substitution \(\varphi=\frac{\pi}{2}-\theta\),
      \(-d\varphi=d\theta\), }
    &=\int_0^{\frac{\pi}{2}}\ln(\sin\theta)\diff\theta
      +\int_{\frac{\pi}{2}}^0\ln(\sin\varphi)\diff\varphi\\
    &=0.
  \end{align*}

  For (vii), note that \(E(\rme^X)=m(1)\) where \(m\) is the MGF of
  \(X\). However, since the first term in the sequence \(m_1=E(X)\) is
  undefined, it follows that \(m(1)\) is undefined so, in particular,
  \(E(\rme^X)\) is undefined.

  Lastly, for (viii), we have
  \begin{align*}
    E(\rme^{-|X|})
    &=\frac{1}{\pi}\int_{-\infty}^\infty\frac{\rme^{-|x|}}{x^2+1}\diff x\\
    &=\frac{2}{\pi}\int_0^{\infty}\frac{\rme^{-x}}{x^2+1}\diff x\\
    &\leq\frac{2}{\pi}\int_0^\infty\frac{1}{x^2+1}\diff x\\
    &=\frac{2}{\pi}\left(\frac{\pi}{2}-0\right)\\
    &=1.
  \end{align*}
  Thus, \(E(\rme^{-|X|})\) exists and is finite.
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 16]
  Give an example of each of the following phenomena:
  \begin{enumerate}[label=(\alph*),noitemsep]
  \item A continuous random variable taking values in \([0,1]\) with equal
    mean and median.
  \item A continuous random variable taking values in \([0,1]\) with mean
    equal to twice the median.
  \item A continuous random variable for which the mean does not exist.
  \item A continuous random variable for which the mean exists, but the
    variance does not exist.
  \item A continuous random variable with a PDF that is not differentiable
    at zero.
  \item a positive continuous random variable for which the mode is zero,
    but the mean does not exist.
  \item A continuous random variable for which all moments exist.
  \item A continuous random variable with median equal to zero, and
    \(25\)\textsup{th} and \(75\)\textsup{th} percentiles equal to \(1\).
  \item A continuous random variable \(X\) with mean equal to median equal
    to mode equal to zero, and \(E(\sin X)=0\).
  \end{enumerate}
\end{problem}
\begin{solution}
  First, note that \([0,1]\) is a probability space under the standard
  Lebesgue measure on \(\bbR\). Therefore, it makes sense to consider
  \(X\colon[0,1]\to\bbR\) random variables.

  For part (a), consider the random variable \(X\colon[0,1]\to\bbR\)
  defined by \(x\mapsto x\) with \(X\sim\Uniform[0,1]\). Then the mean is
  \[
    \mu=\int_{-\infty}^\infty xf(x)\diff x=\int_0^1 x\diff x=\frac{1}{2}
  \]
  and the median is
  \[
    m=\inf\left\{\,x:F(x)=x\geq 0.5\,\right\}=\frac{1}{2}.
  \]

  For part (b), consider again the random variable \(X(x)=x\) for
  \(x\in[0,1]\), but this time let
  \[
    f(x)=
    \begin{cases}
      &\text{},\\
      &\text{}.
    \end{cases}
  \]
  be the PDF of \(X\). Then the mean is
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 17]
  An exponential random variable with mean \(4\) is known to be larger than
  \(6\). What is the probability that it is larger than \(8\)?
\end{problem}
\begin{solution}
  First, since the mean of \(X\) is \(\lambda\defeq 4\), the distribution
  of \(X\) is given by
  \[
    f(x)=
    \begin{cases}
      \frac{1}{4}\rme^{-\frac{x}{4}}&\text{if \(x\geq 0\),}\\
      0&\text{otherwise.}
    \end{cases}
  \]
  Since the distribution is memoryless, we have
  \begin{align*}
    P(X>8|X>6)
    &=P(X>2)\\
    &=\frac{1}{4}\int_2^\infty\rme^{-\frac{x}{4}}\diff x\\
    &=\rme^{-\frac{1}{2}}\\
    &\approx\num{0.6065306597126334}.
  \end{align*}
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 18]
  \emph{(Sum of Gammas).} Suppose \(X\), \(Y\) are independent random
  variables, and \(X\sim \Gamma(\alpha,\lambda)\),
  \(Y\sim \Gamma(\beta,\lambda)\). Find the distribution of \(X+Y\) by
  using moment-generating functions.
\end{problem}
\begin{solution}
  Suppose \(X\) and \(Y\) are independent random variables. Computing the
  MGF of \(X+Y\), we have
  \begin{align*}
    m_{X+Y}(t)
    &=E(\rme^{t(X+Y)})\\
    &=E(\rme^{tX})E(\rme^{tY})\\
    &=\left(1-\frac{t}{\lambda}\right)^{-\alpha}\left(1-\frac{t}{\lambda}\right)^{-\beta}\\
    &=\left(1-\frac{t}{\lambda}\right)^{-\alpha-\beta}.
  \end{align*}
  Since the MGF uniquely determines the distribution, it follows that
  \(X+Y\sim\Gamma(\alpha+\beta,\lambda)\).
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 19]
  \emph{(Product of Chi Squares).} Suppose \(X_1,X_2,\dotsc,X_n\) are
  independent chi square variables, with \(X_i\sim\chi_{m_i}^2\). Find the
  mean and variance of \(\prod_{i=1}^n X_i\).
\end{problem}
\begin{solution}
  Since the \(X_1,\dotsc,X_n\) are independent, the mean of
  \(X\defeq\prod_{i=1}^n X_n\) is
  \begin{align*}
    E(X)
    &=\prod_{i=1}^n E(X_i)\\
    &=\prod_{i=1}^n m_i
  \end{align*}
  and the variance is
  \begin{align*}
    \Var(X)
    &=\prod_{i=1}^n\left[\Var(X_i)+E(X_1)^2\right]-\prod_{i=1}^nE(X_i)^2\\
    &=\prod_{i=1}^n\left(2m_i+m_i^2\right)-\prod_{i=1}^n m_i^2.\qedhere
  \end{align*}
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 20]
  Let \(Z\sim\Normal(0,1)\). Find
  \[
    \begin{aligned}
      P\left( 0.5<\left|Z-\frac{1}{2}\right|<1.5\right);
      && P\left(\frac{\rme^Z}{1+\rme^Z}>\frac{3}{4}\right);
      &&P(\Phi(Z)<0.5).
    \end{aligned}
  \]
\end{problem}
\begin{solution}

\end{solution}
\newpage

\begin{problem}[Handout 13, \# 21]
  Let \(Z\sim\Normal(0,1)\). Find the density of \(\frac{1}{Z}\). Is the
  density bounded?
\end{problem}
\begin{solution}
  Since \(g(x)=\frac{1}{x}\) is monotone decreasing, by the Jacobian
  formula
  \begin{align*}
    f_{\frac{1}{Z}}(x)
    &=\frac{f(g^{-1}(x))}{|g'(g^{-1}(x))|}\\
    &=\frac{1}{\sqrt{2\pi}}
      \frac{\rme^{-\frac{1}{2x^2}}}{\left|-\frac{1}{\left(\frac{1}{x}\right)^2}
      \right|}\\
    &=\frac{1}{\sqrt{2\pi}x^2}\rme^{-\frac{1}{2x^2}}.
  \end{align*}

  The only point at which the we may have a problem with the PDF of
  \(\frac{1}{Z}\) is at \(x=0\). To this end, let us examine
  \[
    \lim_{x\to 0}\frac{\rme^{-\frac{1}{2x^2}}}{x^2}.
  \]
  By l'HÃ´pital's rule, we have
  \begin{align*}
    \lim_{x\to 0}\frac{\rme^{-\frac{1}{2x^2}}}{x^2}
    &=\lim_{x\to 0}\frac{\frac{1}{x^2}}{\rme^{\frac{1}{2x^2}}}\\
    &=\lim_{x\to 0}\frac{-\frac{2}{x^3}}{-\frac{1}{x^3}\rme^{\frac{1}{2x^2}}}\\
    &=\lim_{x\to 0}\frac{2}{\rme^{\frac{1}{2x^2}}}\\
    &=\lim_{x\to 0} 2\rme^{-\frac{1}{2x^2}}\\
    &=0.
  \end{align*}
  With this same argument, we see that \(\lim_{x\to\pm\infty}
  f_{\frac{1}{Z}}(x)<\infty\) and indeed since \(f_{\frac{1}{Z}}\) is
  continuous at every other point, it is bounded.
\end{solution}
\newpage

\begin{problem}[Handout 13, \# 22]
  The \(25\)\textsup{th} and the \(75\)\textsup{th} percentile of a
  normally distributed random variable are \(-1\) and \(1\). What is the
  probability that the random variable is between \(-2\) and \(2\)?
\end{problem}
\begin{solution}

\end{solution}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../MA519-HW-Current"
%%% End:
