\begin{problem}[Handout 7, \# 6(d, f)]
  Find the variance of the following random variables
  \begin{itemize}[noitemsep]
  \item[(d)] \(X=\#\) of tosses of a fair coin necessary to obtain a head
    for the first time.
  \item[(f)] \(X=\#\) matches observed in random sitting of \(4\) husbands
    and their wives in opposite sides of a linear table.

    This is an example of the \emph{matching problem.}
  \end{itemize}
\end{problem}
\begin{solution}
  Recall that the variance of a random variable can be computed as
  \[
    \Var(X)=E(X^2)-E(X)^2.
  \]

  For part (d), let \(X\) be as above. First, note that \(X\) takes every
  value on \(\bbN\). Thus, its PMF is
  \[
    p(n)=P(X=n)=\frac{1}{2^n}
  \]
  and its expectation the value of the series
  \[
    E(X)=\sum_{n=1}^\infty \frac{n}{2^n}.
  \]
  Using a little bit of analysis we can find the value of \(E(X)\), e.g.,
  by considering the function \(f(x)\defeq\sum_{n=1}^\infty nx^{n-1}\), taking its
  indefinite integral, and noting that it is a geometric series sans the
  first term. Concretely,
  \[
    \int f(x)\diff x=\sum_{n=1}^\infty x^n=-1+\sum_{n=0}^\infty x^n,
  \]
  which, for \(|x|<1\), converges to the value \(x/(1-x)\). Taking the
  derivative of this, we have \(1/(1-x)^2\). Thus,
  \begin{align*}
    E(X)&=\sum_{n=1}^\infty \frac{n}{2^n}\\
        &=\frac{1}{2}\sum_{n=1}^\infty\frac{n}{2^{n-1}}\\
        &=\frac{1/2}{\bigl(1-(1/2)\bigr)^2}\\
        &=2.
  \end{align*}
  This is the mean of \(X\).

  Next we must compute the mean of \(X^2\). We have already computed the
  PMF of \(X\) hence,
  \[
    E(X^2)=\sum_{n=1}^\infty\frac{n^2}{2^n}.
  \]
  To find the limit of this series, we can use a similar method to the one
  in the last paragraph. That is, consider the function \(g(x)\defeq
  \sum_{n=1}^\infty n^2x^{n-1}\). Taking its integral, we have
  \[
    xG(x)=\int g(x)\diff x=\sum_{n=1}^\infty nx^n=x\sum_{n=1}^\infty nx^{n-1}
  \]
  and repeat this on \(G\), giving us
  \[
    \int G(x)\diff x=\sum_{n=1}^\infty x^n=-1+\sum_{n=0}^n x^n=\frac{x}{1-x}.
  \]
  Tracing back our steps,
  \[
    \int g(x)=\frac{x}{(1-x)^2}
  \]
  so
  \[
    g(x)=\frac{1-x^2}{(1-x)^4}.
  \]
  Thus,
  \begin{align*}
    E(X)
    &=\frac{1}{2}\sum_{n=1}^\infty\frac{n}{2^{n-1}}\\
    &=\frac{(1/2)\bigl(1-(1/2)^2\bigr)}{\bigl(1-(1/2)\bigr)^4}\\
    &=6.
  \end{align*}

  Putting all of this together, the variance is
  \[
    \boxed{\Var(X)=6-(2)^2=2.}
  \]
  \\\\
  For part (f), again, we let \(X\) be as above. The PMF of \(X\) is given
  by
  \[
    P(X=n)=
  \]
\end{solution}
\newpage

\begin{problem}[Handout 7, \# 8]
  \emph{(Nonexistence of variance).}
  \begin{enumerate}[label=(\alph*),noitemsep]
  \item Show that for a suitable positive constant \(c\), the function
    \(p(x)=c/x^3\), \(x=1,\dots\), is a valid probability mass function
    (PMF).
  \item Show that in this case, the expectation of the underlying random
    variable exists, but the variance does not!
  \end{enumerate}

\end{problem}
\begin{solution}
  For part (a), note that $p(x)$ given above satisfies the requirements to
  be a probability mass function. First, set
  $1/c = \sum_{x=1}^\infty 1/x^3$, and note that indeed $c$ is well defined
  (because the relevant series converges, by the \(p\)-test.)

  This means that $1=\sum_{x=1}^\infty c/x^3 = \sum p(x)$, by
  definition. Moreover, because $p(x) = c/x^3 > 0$ for all $x$ in our
  domain, $p(x) \in [0,1]$. That is, $p$ is a valid probability mass
  function.

  Set $X$ equal to the random variable described by $p$. Next, note that
  \begin{align*}
    E(X) &= \sum_{n=1}^\infty n \frac{c}{n^3}\\
         &= \sum_{n=1}^\infty \frac{c}{n^2}\\
  \end{align*}
  which converges (and thus exists), again by the \(p\)-test.

  However,
  \begin{align*}
    E(X^2) &= \sum_{n=1}^\infty n^2 \frac{c}{n^3}\\
           &= \sum_{n=1}^\infty \frac{c}{n}\\
  \end{align*}
  which does not converge, again by the \(p\)-test. That is, the variance
  $E(X^2)-E(X)^2$ does not exist.
\end{solution}
\newpage

\begin{problem}[Handout 7, \# 9]
  In a box, there are \(2\) black and \(4\) white balls. These are drawn
  out one by one at random (without replacement).
  \begin{enumerate}[label=(\alph*),noitemsep]
  \item Let \(X\) be the draw at which the first black ball comes out. Find
    the mean the variance of \(X\).
  \item Let \(X\) be the draw at which the second black ball comes
    out. Find the meman\footnote{What is a meman? How do you pronounce
      meman? Is it mee-man or muh-man?} the variance of \(X\).
  \end{enumerate}
\end{problem}
\begin{solution}
  For part (a), we must first find the PMF of \(X\). This we do explicitly,
  \begin{align*}
    P(X=1)&=\frac{2}{6}=\frac{1}{3},
    &P(X=2)&=\frac{2}{5}\cdot\frac{4}{6}=\frac{4}{15},\\
    P(X=3)&=\frac{2}{4}\cdot\frac{3}{5}\cdot\frac{4}{6}=\frac{1}{5},
    &P(X=4)&=\frac{2}{3}\cdot\frac{2}{4}\cdot\frac{3}{5}\cdot\frac{4}{6}=\frac{2}{15},\\
    P(X=5)&=1\cdot\frac{1}{3}\cdot\frac{2}{4}\cdot\frac{3}{5}\cdot\frac{4}{6}=\frac{1}{15}.
  \end{align*}
  Thus,
  \[
    \boxed{
      \begin{aligned}
        E(X)
        &=1\cdot\frac{1}{3}+2\cdot\frac{4}{15}+3\cdot\frac{1}{5}+4\cdot\frac{2}{15}+5\cdot\frac{1}{15}\\
        &=\frac{7}{3}\\
        &=\num{2.3333333}.
      \end{aligned}}
  \]

  Similarly, we have
  \[
    \begin{aligned}
      E(X^2)
      &=1^2\cdot\frac{1}{3}+2^2\cdot\frac{4}{15}+3^2\cdot\frac{1}{5}+4^2\cdot\frac{2}{15}+5^2\cdot\frac{1}{15}\\
      &=7.
    \end{aligned}
  \]

  Hence,
  \[
    \boxed{\Var(X)=7-\left(\frac{7}{3}\right)^2\approx\num{1.55555}.}
  \]

  For part (b) we have a similar setup. We compute the PMF of \(X\)
  explicitly
  \begin{align*}
    P(X=2)&=\frac{2}{6}\cdot\frac{1}{5}=\frac{1}{15},
    &P(X=3)&=\frac{4}{6}\cdot\frac{2}{5}\cdot\frac{1}{4}+\frac{2}{6}\cdot\frac{4}{5}\cdot\frac{1}{4}
           =\frac{2}{15},\\
    P(X=4)&=3\cdot\frac{4}{6}\cdot\frac{3}{5}\cdot\frac{2}{4}\cdot\frac{1}{3}
          =\frac{3}{15},
    &P(X=5)&=4\cdot\frac{4}{6}\cdot\frac{3}{5}\cdot\frac{2}{4}
           \cdot\frac{2}{3}\cdot\frac{1}{2}
           =\frac{4}{15},\\
    P(X=6)&=5\cdot\frac{4}{6}\cdot\frac{3}{5}\cdot
          \frac{2}{4}\cdot\frac{1}{3}\cdot\frac{2}{2}\cdot 1
          =\frac{5}{15}.
  \end{align*}
  Thus,
  \[
    \boxed{
      \begin{aligned}
        E(X)
        &=\frac{2+3\cdot 2+4\cdot 3+5\cdot 4+6\cdot 5}{15}\\
        &=\frac{14}{3}\\
        &\approx\num{4.666666666666667}.
      \end{aligned}
    }
  \]

  Similarly,
  \begin{align*}
    E(X^2)
    &=\frac{2^2+3^2\cdot 2+4^2\cdot 3+5^2\cdot 4+6^2\cdot 5}{15}\\
    &=\frac{70}{3}\\
    &\approx\num{23.333333333333332}.
  \end{align*}

  Thus,
  \[
    \boxed{\Var(X)\approx
      \frac{70}{3}-\left(\frac{14}{3}\right)^2\approx\num{1.55555555555555}.}
  \]
\end{solution}
\newpage

\begin{problem}[Handout 7, \# 10]
  Suppose \(X\) has a \emph{discrete uniform distribution} on the set
  \(\{1,\dotsc,N\}\).
  \\\\
  Find formulas for the mean and the variance of \(X\).
\end{problem}
\begin{solution}

  First, we find the mean:
  \begin{align*}
    E(X) &= \sum_{n=1}^N n \frac{1}{N}\\
         &= \frac{1}{N} \frac{N(N+1)}{2}\\
         &=\frac{(N+1)}{2}
  \end{align*}

  Next, we find the variance:
\begin{align*}
  E(X^2) - E(X)^2
  &= \sum_{n=1}^N n^2 \frac{1}{N} - \left[\frac{(N+1)}{2}\right]^2\\
  &=\frac{N^2}{3}+\frac{N}{2}+\frac{1}{6}-\left[\frac{(N+1)}{2}\right]^2\\
  &=\frac{N^2-1}{12}
                  % &=  \frac{\pi^2}{6N} - \left(\frac{(N+1)}{2}\right)^2.
\end{align*}
\end{solution}
\newpage

\begin{problem}[Handout 7, \# 11]
  \emph{(Be Original)} Give an example of a random variable with mean
  \(1\) and variance \(100\).
\end{problem}
\begin{solution}
  Let $X$ be the random variable whose PMF is given by
  \begin{align*}
    P(X = -10-1) &= 0.5\\
    P(X = 10-1) &= 0.5\\
    P\bigl(X \neq \pm \sqrt{10}-1\bigr) &= 0\\
  \end{align*}
  (Note that those expressions are very easy to simplify (-10-1 =-11,
  10-1=9), but leaving them in that form makes the arithmetic more
  obvious.)

  Then we see that the mean of $X$ is given by
  \begin{align*}
    E(X) &= 0.5 (-10-1 +10-1)\\
         &= 1
  \end{align*}
  and the variance of $X$ is given by
  \begin{align*}
    E((X-E(X))^2) &= E((X-1)^2) \\
                  &= 0.5 (10^2 + (-10)^2) \\
                  &= 0.5 (10^2 + (-10)^2) \\
                  &= 100
  \end{align*}
  so that $X$ is such a random variable as described in the problem.
\end{solution}
\newpage

\begin{problem}[Handout 7, \# 13]
  \emph{(Be Original).} Suppose a random variable \(X\) has the property
  that its second and fourth moment are both \(1\).
  \\\\
  What can you say about the nature of \(X\)?
\end{problem}
\begin{solution}

\end{solution}
\newpage

\begin{problem}[Handout 7, \# 14]
  \emph{(Be Original).} One of the following inequalities is true in
  general for all nonnegative random variables. Identify which one!
  \begin{align*}
    E(X)E(X^4)&\geq E(X^2)E(X^3);\\
    E(X)E(X^4)&\leq E(X^2)E(X^2).
  \end{align*}
\end{problem}
\begin{solution}

\end{solution}
\newpage

\begin{problem}[Handout 7, \# 15]
  Suppose \(X\) is the number of heads obtained in \(4\) tosses of a fair
  coin.

  Find the expected value of the weird function
  \[
    \log\bigl( 2+\sin(\tfrac{\pi}{4}x) \bigr).
  \]
\end{problem}
\begin{solution}
  First, note that
  \begin{align*}
    P(X=0) &= \frac{1}{16},&
    P(X=1) &= \frac{4}{16},\\
    P(X=2) &= \frac{6}{16},&
    P(X=3) &= \frac{4}{16},\\
    P(X=4) &= \frac{1}{16}.\\
  \end{align*}
  Thus, computing the expected value of the function, we get
  \begin{align*}
    E\left[\log\bigl( 2+\sin(\tfrac{\pi}{4}X) \bigr)\right]
    &= \sum_{x=0}^4 p(X=x)\log\bigl( 2+\sin(\tfrac{\pi}{4}x) \bigr)\\
    &= \frac{1}{16} \left[\log(2) +4 \log \bigl(2+\tfrac{\sqrt{2}}{2}
      \bigr) +6 \log (2+1) +4 \log \bigl(2+\tfrac{\sqrt{2}}{2}
      \bigr) + \log(2)\right]\\
    &=\frac{1}{16} \left[2\log(2) +8 \log \bigl(2+\tfrac{\sqrt{2}}{2}
      \bigr) +6 \log (3) \right]\\
    &\approx 0.9966.
  \end{align*}
\end{solution}
\newpage

\begin{problem}[Handout 7, \# 16]
  In a sequence of Bernoulli trials let \(X\) be the length of the run (of
  either successes or failures) started by the first trial.
  \begin{itemize}[noitemsep]
  \item[(a)] Find the distribution of \(X\), \(E(X)\), \(\Var(X)\).
  % \item[(b)] Let Y be the length of the second run. Find the distribution
  %   of Y, E(Y), Var (Y), and the joint distribution of X, Y.
  \end{itemize}
\end{problem}
\begin{solution}

\end{solution}
\newpage

\begin{problem}[Handout 7, \# 17]
  A man with \(n\) keys wants to open his door and tries the keys
  independently and at random. Find the mean and variance of the number of
  trials
  \begin{itemize}[noitemsep]
  \item[(a)] if unsuccessful keys are not eliminated from further
    selections;
  \item[(b)] if they are.
  \end{itemize}
  (Assume that only one key fits the door. The exact distributions are
  given in II, 7, but are not required for the present problem.)
\end{problem}
\begin{solution}

\end{solution}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../MA519-Current-HW"
%%% End:
